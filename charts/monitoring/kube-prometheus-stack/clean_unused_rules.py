#!/usr/bin/env python3

import yaml
from pathlib import Path

def clean_unused_rules():
    """ë§¤í•‘ë˜ì§€ ì•Šì€ jobì„ ì‚¬ìš©í•˜ëŠ” ê·œì¹™ë“¤ ì œê±°"""
    
    # ìœ ì§€í•  jobë“¤ (ë§¤í•‘ëœ ê²ƒë“¤)
    allowed_jobs = {
        'kubernetes-service-endpoints',
        'kubernetes-nodes-cadvisor', 
        'kubernetes-apiservers'
    }
    
    input_file = Path("prometheus-rules-standard/rules-updated.yml")
    output_file = Path("prometheus-rules-standard/rules-clean.yml")
    
    print("ğŸ§¹ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê·œì¹™ë“¤ ì œê±° ì¤‘...")
    print("=" * 50)
    
    # YAML íŒŒì¼ ë¡œë“œ
    with open(input_file, 'r', encoding='utf-8') as f:
        rules_data = yaml.safe_load(f)
    
    cleaned_groups = []
    removed_stats = {'groups': 0, 'rules': 0}
    
    for group in rules_data.get('groups', []):
        cleaned_rules = []
        group_name = group.get('name', 'unknown')
        
        for rule in group.get('rules', []):
            expr = rule.get('expr', '')
            
            # job="..." íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸
            has_job_filter = 'job="' in expr
            
            if has_job_filter:
                # í—ˆìš©ëœ jobì¸ì§€ í™•ì¸
                has_allowed_job = any(f'job="{job}"' in expr for job in allowed_jobs)
                
                if has_allowed_job:
                    cleaned_rules.append(rule)
                else:
                    removed_stats['rules'] += 1
                    print(f"  âŒ ì œê±°: {group_name} - {rule.get('alert', rule.get('record', 'unknown'))}")
            else:
                # job í•„í„°ê°€ ì—†ëŠ” ê·œì¹™ì€ ìœ ì§€
                cleaned_rules.append(rule)
        
        # ê·œì¹™ì´ ë‚¨ì•„ìˆëŠ” ê·¸ë£¹ë§Œ ìœ ì§€
        if cleaned_rules:
            group['rules'] = cleaned_rules
            cleaned_groups.append(group)
            print(f"  âœ… ìœ ì§€: {group_name} ({len(cleaned_rules)}ê°œ ê·œì¹™)")
        else:
            removed_stats['groups'] += 1
            print(f"  ğŸ—‘ï¸  ê·¸ë£¹ ì œê±°: {group_name} (ëª¨ë“  ê·œì¹™ ì œê±°ë¨)")
    
    # ì •ë¦¬ëœ ë°ì´í„° ì €ì¥
    cleaned_data = {'groups': cleaned_groups}
    
    with open(output_file, 'w', encoding='utf-8') as f:
        yaml.dump(cleaned_data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    
    print(f"\nğŸ“ ì •ë¦¬ëœ íŒŒì¼: {output_file}")
    print(f"ğŸ“Š ì •ë¦¬ ê²°ê³¼:")
    print(f"   â€¢ ì œê±°ëœ ê·¸ë£¹: {removed_stats['groups']}ê°œ")
    print(f"   â€¢ ì œê±°ëœ ê·œì¹™: {removed_stats['rules']}ê°œ") 
    print(f"   â€¢ ë‚¨ì€ ê·¸ë£¹: {len(cleaned_groups)}ê°œ")
    
    # ë‚¨ì€ ê·œì¹™ ìˆ˜ ê³„ì‚°
    total_remaining_rules = sum(len(group.get('rules', [])) for group in cleaned_groups)
    print(f"   â€¢ ë‚¨ì€ ê·œì¹™: {total_remaining_rules}ê°œ")
    
    # ìœ ì§€ëœ jobë“¤ í™•ì¸
    check_remaining_jobs_in_clean_file(output_file)

def check_remaining_jobs_in_clean_file(file_path):
    """ì •ë¦¬ëœ íŒŒì¼ì—ì„œ ë‚¨ì€ jobë“¤ í™•ì¸"""
    
    import re
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    job_patterns = re.findall(r'job="([^"]+)"', content)
    remaining_jobs = {}
    
    for job in job_patterns:
        if job not in remaining_jobs:
            remaining_jobs[job] = 0
        remaining_jobs[job] += 1
    
    print(f"\nâœ… ì •ë¦¬ëœ íŒŒì¼ì˜ job ë¶„í¬:")
    for job, count in sorted(remaining_jobs.items(), key=lambda x: x[1], reverse=True):
        print(f"   â€¢ {job:<35} ({count}íšŒ)")

if __name__ == "__main__":
    clean_unused_rules()