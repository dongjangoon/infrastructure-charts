# Fluent Bit Official Helm Chart values
image:
  repository: fluent/fluent-bit
  tag: "4.0"

serviceAccount:
  create: true

rbac:
  create: true

daemonSetVolumes:
  - name: varlog
    hostPath:
      path: /var/log
  - name: varlibdockercontainers
    hostPath:
      path: /var/lib/docker/containers

daemonSetVolumeMounts:
  - name: varlog
    mountPath: /var/log
  - name: varlibdockercontainers
    mountPath: /var/lib/docker/containers
    readOnly: true

config:
  service: |
    [SERVICE]
        Daemon off
        Flush 5
        Log_Level info
        Parsers_File parsers.conf
        HTTP_Server On
        HTTP_Listen 0.0.0.0
        HTTP_Port 2020
        # 버퍼링 설정
        storage.metrics on
        storage.path /tmp/flb-storage/
        storage.sync normal
        storage.checksum off
        storage.backlog.mem_limit 50M

  inputs: |
    [INPUT]
        Name tail
        Path /var/log/containers/*.log
        multiline.parser cri
        Tag kube.*
        Mem_Buf_Limit 50MB
        Skip_Long_Lines On
        Skip_Empty_Lines On
        # 백프레셔 처리
        storage.type filesystem

  filters: |
    [FILTER]
        Name kubernetes
        Match kube.*
        Kube_URL https://kubernetes.default.svc:443
        Kube_CA_File /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File /var/run/secrets/kubernetes.io/serviceaccount/token
        Kube_Tag_Prefix kube.var.log.containers.
        Merge_Log On
        K8S-Logging.Parser On
        K8S-Logging.Exclude Off
        Labels On

    [FILTER]
        Name modify
        Match kube.*
        Add cluster_name {{ .Values.clusterName }}
        Add environment {{ .Values.environment }}

  outputs: |
    [OUTPUT]
        Name kafka
        Match kube.*
        Format json
        Brokers {{ .Values.kafka.brokers }}
        Topics {{ .Values.kafka.topic }}
        Timestamp_Key @timestamp
        Timestamp_Format %Y-%m-%dT%H:%M:%S.%LZ
        # 신뢰성 설정
        Retry_Limit 5
        rdkafka.request.timeout.ms 30000
        rdkafka.message.timeout.ms 300000
        rdkafka.acks all
        rdkafka.compression.type gzip
        # 배치 처리로 성능 향상
        rdkafka.batch.size 16384
        rdkafka.linger.ms 100

  parsers: |
    [PARSER]
        Name cri
        Format regex
        Regex ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$
        Time_Key time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z

# 커스텀 값들
clusterName: "cluster1"
environment: "test"
kafka:
  brokers: "${KAFKA_BROKER_IP}:9092"
  topic: "kubernetes-logs"

resources:
  limits:
    memory: 200Mi
    cpu: 200m
  requests:
    memory: 100Mi
    cpu: 100m

tolerations:
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule
  - operator: "Exists"
    effect: "NoExecute"
  - operator: "Exists"
    effect: "NoSchedule"
  - key: gpu
    operator: Equal
    value: "true"
    effect: NoSchedule
